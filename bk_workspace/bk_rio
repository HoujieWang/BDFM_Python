import os
import matplotlib.pyplot as plt
import scipy.linalg
import geopandas as gpd
from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)
import numpy as np
import pandas as pd
from datetime import datetime
import time
import math
import matplotlib.pyplot as plt
import matplotlib.dates
import matplotlib.colors as mcolors
from sklearn.preprocessing import normalize
import importlib
import sys
import itertools

import random
os.chdir("bk_workspace/Utilities")
#importlib.reload(SimulatePath.SimulatePath)
from Poisson import FF_Poisson, RA_Poisson
from Bernoulli import FF_Bernoulli, RA_Bernoulli
from Recouple_DGM2 import Recouple_DGM2
from BK_functions import RA_Poisson_BK, RA_Bernoulli_BK, FF_Poisson_BK, FF_Bernoulli_BK
from SimulatePath import SimulatePath, SimulatePath2



""" del sys.modules['SimulatePath']
os.chdir("bk_workspace/Utilities")
from SimulatePath import SimulatePath, SimulatePath2
os.chdir("../..") """

#### Load Rio bus data and shapfile 

os.chdir("../../../rio_buses/bus_gps_data")

busData = pd.read_csv('treatedBusDataOnlyRoute.csv')
busData['longitude'] = pd.to_numeric(busData.longitude, errors='coerce')
busData['latitude'] = pd.to_numeric(busData.latitude, errors='coerce')

os.chdir("../../Github")
sf = gpd.read_file("Houjie's Code/Run Rio Data/RioShapeFile/33MUE250GC_SIR.shp")
rio = sf[sf.ID == 1535] # ID of the city of Rio

# Generate spatial grid points
rio_bounds = np.array(rio.bounds).reshape(4,)
cell_size = 0.05 # grid cell size 
lon_coords = np.arange(rio_bounds[0], rio_bounds[2]+cell_size, cell_size) 
lat_coords = np.arange(rio_bounds[1], rio_bounds[3]+cell_size, cell_size)
rio_grid = np.array(np.meshgrid(lon_coords, lat_coords)).\
    reshape(2, len(lon_coords)*len(lat_coords)).T


# Specify a specific bus line within a day
all_bus_line = np.unique(busData.line)
# bus_date = '01-25-2019'; 
# bus_date = ['01-25-2019', '01-26-2019']

bus_subgrid = busData[(-43.3 <= busData.longitude) & (busData.longitude <= -43.2) & \
    (-23 <= busData.latitude) & (busData.latitude <= -22.8)]
busline_subgrid = np.unique(bus_subgrid.line)

days = 1
bus_date = pd.date_range('02-18-2019', periods=days, freq='24h').strftime('%m-%d-%Y')
sub_bus = busData[np.isin(np.array(busData.line), busline_subgrid[0: 20]) &  \
                  np.isin(busData.date, bus_date) \
                    # & (busData.order == bus_order)
                    ]


bus_time = np.array([np.datetime64(datetime.strptime(t, '%m-%d-%Y%H:%M:%S')) \
                        for t in np.array(sub_bus.date) + np.array(sub_bus.time)])

# Generate time grid points
time_intl = '30min'
period = 48
time_grid = pd.date_range(bus_date[0], periods=period*1*len(bus_date), freq=time_intl)
# time_grid = time_grid[(np.where(time_grid >= np.min(bus_time))[0][0]-1): len(time_grid)]

bus_id = np.unique(sub_bus.order)
bus_location = (np.zeros((len(bus_id), len(time_grid)-1))-1).astype("int")
for i in range(len(time_grid)-1):
    # i = 0
    print(i)
    t0 = time_grid[i]
    t1 = time_grid[i+1]
    sub_bus_tmp = sub_bus.iloc[(t0 < bus_time) & (bus_time < t1), ]
    for j in range(len(bus_id)):
        print("Running bus", j, "at time ", t0)
        # bus = 'D13022'
        bus = bus_id[j]
        if (sum(sub_bus_tmp.order == bus) != 0):
            sub_bus_tmp_i = sub_bus_tmp.iloc[np.array(sub_bus_tmp.order == bus), :]
            # the point is the largest lat,long point that are smaller than 
            # the bus's latest lat,long point in the current time interval
            lon_point = lon_coords[np.where(lon_coords > sub_bus_tmp_i.longitude.iloc[-1])[0][0]-1]
            lat_point = lat_coords[np.where(lat_coords > sub_bus_tmp_i.latitude.iloc[-1])[0][0]-1]
            
            index = np.where((rio_grid[:,0] == lon_point) & (rio_grid[:,1] == lat_point))[0][0]
            bus_location[j, i] = index
            
        
# After we obtain the bus location at each period, we get the flows
edge_idx = [None] * (bus_location.shape[1]-1)
last_location = bus_location[:, 0]
for i in np.arange(1,bus_location.shape[1]):
    # i = 1
    bus_location_i = np.vstack([last_location, bus_location[:, i]]).T
    # only check buses with observed location in both periods
    edgeIndex_tmp = bus_location_i[np.sum(bus_location_i[:, 0:2] != -1, axis = 1) == 2, ] 
    last_location[bus_location_i[:, 1] != -1] = bus_location_i[bus_location_i[:, 1] != -1, 1]
    edge_idx[i-1] = edgeIndex_tmp[edgeIndex_tmp[:, 0] != edgeIndex_tmp[:, 1], :]
    
    


unique_edges = np.unique(np.vstack([edge_idx[i] for i in range(len(edge_idx))]), axis = 0)
flow_count = np.zeros((unique_edges.shape[0], len(edge_idx)))

unique_nodes = np.unique(unique_edges)
out_flows = np.zeros((len(unique_nodes), len(edge_idx)))
for j in range(len(edge_idx)):
    # edge_i = np.array([981, 1053])
    for k in range(len(unique_nodes)):
        # k = 0
        node = unique_nodes[k]
        out_flows[k, j] = np.sum(edge_idx[j][:, 0] == node)
        
    for i in range(unique_edges.shape[0]):
        edge_i = unique_edges[i, :]
        flow_count[i, j] = \
        np.sum((edge_i[0] == edge_idx[j][:, 0]) & (edge_i[1] == edge_idx[j][:, 1]))
        
out_flows = out_flows.T      

# Now the flow_count, unique_edges, m are the flows for each edge, edge ID, occupancy ratio
TTotal, I = out_flows.shape
T0= 0
TActual = TTotal - T0
m = np.zeros((TActual,I), dtype = 'double')
m[:, (I-1)] = 1
for t in range(TActual):
    for i in range(I):
        if out_flows[t+T0,i] == 0:
            m[t,i] = 0;
        elif out_flows[t+T0, i] <= 10 or out_flows[t+T0-1, i] <= 10:
            m[t, i] = 1
        else:
            m[t, i] = out_flows[t+T0, i]/out_flows[t+T0-1, i]


############################## Fitting DCMM ##################################


eps = 1e-2
flow_count[flow_count == 0] = eps
N = flow_count.shape[0]
period = 48

# Bernoulli

F_bern = np.array([[1],
                     [0]])
G_bern = np.array([[1, 1], 
                     [0, 1]])
F_bern = np.array([[1],
                    [0],
                    [1],
                    [0]])

G_bern = scipy.linalg.block_diag([[1, 1], 
                                [0, 1]],
                                [[np.cos(2*np.pi/period), np.sin(2*np.pi/period)],
                                [-np.sin(2*np.pi/period), np.cos(2*np.pi/period)]])

delta_bern = 0.99  # Discount factor for evolution variance
sampleSize_bern = 100 # Sample size of posterior and predictions

# Poisson
F_pois = np.array([[1],
                     [0]])
G_pois = np.array([[1, 1], 
                    [0, 1]])
F_pois = np.array([[1],
                    [0],
                    [1],
                    [0]])
G_pois = scipy.linalg.block_diag([[1, 1], 
                                [0, 1]],
                                [[np.cos(2*np.pi/period), np.sin(2*np.pi/period)],
                                [-np.sin(2*np.pi/period), np.cos(2*np.pi/period)]])

# Augment for Random Effect
F_pois = np.r_[np.array([[1]]), F_pois]
G_pois = scipy.linalg.block_diag(0, G_pois)

delta_pois = 0.99  # Discount factor for evolution variance
RE_rho_pois = .9 # Discount factor for random effect. When = 1, no RE
conditional_shift_pois = 1 # Shift of conditional Poisson
sampleSize_pois = 100 # Sample size of posterior and predictions

sampleSize_dgm = 100
# Fit all individual dynamic models
phi_samp = np.zeros((N, TActual, sampleSize_dgm))

# Get learned parameters
rt_bern_all = np.zeros((TActual, N))
st_bern_all = np.zeros((TActual, N))
rt_pois_all = np.zeros((TActual, N))
st_pois_all = np.zeros((TActual, N))

ssrt_bern_all = np.zeros((TActual, N))
ssst_bern_all = np.zeros((TActual, N))
ssrt_pois_all = np.zeros((TActual, N))
ssst_pois_all = np.zeros((TActual, N))

nSample = 100
pois_samps = np.zeros((nSample, TActual, N))
bern_samps = np.zeros((nSample, TActual, N))
st = time.time()
for n in range(N):
    # n = 0
    print(n)
    mN = m[:,np.where(unique_nodes == unique_edges[n,0])[0]]
    
    # Forward Filtering
    st = time.time()
    mt_bern, Ct_bern, at_bern, Rt_bern, rt_bern, st_bern, skipped_bern = \
        FF_Bernoulli_BK(F_bern, G_bern, delta_bern, flow_count, n, T0, TActual, eps)
    ed = time.time()
    # ed - st

    st = time.time()
    [mt_pois, Ct_pois, at_pois, Rt_pois, rt_pois, ct_pois, skipped_pois] = \
        FF_Poisson_BK(F_pois, G_pois, delta_pois, flow_count, n, mN, T0, TActual, \
                   eps, RE_rho_pois, conditional_shift_pois)
    ed = time.time()
    # ed - st

    # Retrospective Analysis
    """     st = time.time()
    [sat_bern, sRt_bern, ssrt_bern, ssst_bern, RA_prob] = \
        RA_Bernoulli(TActual, F_bern, G_bern, mt_bern, \
                     Ct_bern, at_bern, Rt_bern, skipped_bern,\
                     nSample = nSample)
    ed = time.time()
    # ed - st

    [sat_pois, sRt_pois, ssrt_pois, ssct_pois, RA_rate] = \
        RA_Poisson(TActual, F_pois, G_pois, mt_pois, \
                   Ct_pois, at_pois, Rt_pois, skipped_pois,
                   nSample = nSample) """
    
    # BK Retrospective_BK
    prob_samps = RA_Bernoulli_BK(TActual, F_bern, G_bern, mt_bern, \
                   Ct_bern, at_bern, Rt_bern, skipped_bern,
                   nSample = nSample)
    rate_samps = RA_Poisson_BK(TActual, F_pois, G_pois, mt_pois, \
                   Ct_pois, at_pois, Rt_pois, skipped_pois,
                   nSample = nSample)
    
    # Store them
    rt_bern_all[:, n] = rt_bern
    st_bern_all[:, n] = st_bern
    rt_pois_all[:, n] = rt_pois
    st_pois_all[:, n] = ct_pois

    """ssrt_bern_all[:, n] = ssrt_bern
    ssst_bern_all[:, n] = ssst_bern
    ssrt_pois_all[:, n] = ssrt_pois
    ssst_pois_all[:, n] = ssct_pois """

    bern_samps[:, :, n] = prob_samps
    pois_samps[:, :,  n] = rate_samps

"""    # Troubleshooting
    [F, G, mt, Ct, at, Rt, skipped, RE_rho, delta, flow] = [F_pois, G_pois, mt_pois, Ct_pois, at_pois, 
                                                      Rt_pois, skipped_pois, RE_rho_pois, delta_pois, flow_count]
    [F, G, mt, Ct, at, Rt, skipped] = [F_bern, G_bern, mt_bern, Ct_bern, at_bern, Rt_bern, skipped_bern] """
bern_mean = np.mean(bern_samps, 0)
bern_mean[ra_bern_mean > 1] = .999
ra_bern_upper = np.quantile(bern_samps, .975, 0)
ra_bern_lower = np.quantile(bern_samps, .025, 0)

pois_mean = np.mean(pois_samps, 0)
ra_pois_upper = np.quantile(pois_samps, .975, 0)
ra_pois_lower = np.quantile(pois_samps, .025, 0)

ff_pois_mean = rt_pois_all / st_pois_all
ff_bern_mean = rt_bern_all / (rt_bern_all + st_bern_all)

sim_paths = SimulatePath(26, 0, 3, bern_samps, pois_samps, unique_edges)
sim_paths = SimulatePath2(54, 20, 23, bern_mean, pois_mean, unique_edges, 100)
sim_strings = [str(row) for row in sim_paths]
uniques = pd.Series(np.unique(sim_strings))
path_probs = uniques.apply(lambda x: np.mean([string == x for string in sim_strings]))



# # Compute transition probabilities
# nSample = 5
# transition_probs = [None]*len(unique_nodes)
# k = 0
# for i in unique_nodes:
#     # i = 2793
#     print(i)
#     edges_i = np.where((unique_edges[:,0] == i))[0]
#     transition_probs_i = np.zeros((TActual, 1+len(edges_i), nSample))
#     for i_sample in range(nSample):
#         pi = np.random.beta(ssrt_bern_all,ssst_bern_all)
        
#         mu = np.random.gamma(ssrt_pois_all,1/ssst_pois_all)
#         # pi = np.random.beta(np.repeat(ssrt_bern_all[:,:,np.newaxis], nSample, axis=2),\
#         #                     np.repeat(ssst_bern_all[:,:,np.newaxis], nSample, axis=2))
        
#         # mu = np.random.gamma(np.repeat(ssrt_pois_all[:,:,np.newaxis], nSample, axis=2),\
#         #                     np.repeat(1/ssst_pois_all[:,:,np.newaxis], nSample, axis=2))

#         temp_mat = np.repeat(1 - pi[:, edges_i][:,:, np.newaxis], edges_i.shape[0], axis=2)
#         all_t, n_outpath = temp_mat.shape[0:2]
        
#         temp_mat[list(np.repeat(np.arange(all_t),n_outpath)), \
#                  list(np.arange(n_outpath))*all_t, \
#                  list(np.arange(n_outpath))*all_t] = \
#             (np.exp(-mu[:, edges_i])*pi[:, edges_i]).reshape(all_t*n_outpath, )
#         transition_probs_i[:, :, i_sample] = \
#             np.hstack((np.prod(1 - pi[:, edges_i], axis=1).reshape(all_t,1), np.prod(temp_mat, axis=1)))
            
#     transition_probs[k] = transition_probs_i / \
#         np.repeat(np.sum(transition_probs_i, axis = 1)[:, np.newaxis, :,], n_outpath+1, axis = 1) 
#     k+=1
    
    

# Decompose fitted data
# fEst_exp, fUpper_exp, fLower_exp, aiEst_exp, aiUpper_exp, aiLower_exp, \
#     bjEst_exp, bjUpper_exp, bjLower_exp, gijEst_exp, gijUpper_exp, gijLower_exp, \
#         MC_f, MC_ai, MC_bj, MC_gij = \
#     Recouple_DGM2(rt_bern_all, st_bern_all, rt_pois_all, st_pois_all,\
#     conditional_shift_pois, \
#     TActual, unique_edges, unique_nodes, 2500, I, N);

fEst_exp_r, fUpper_exp_r, fLower_exp_r, \
    aiEst_exp_r, aiUpper_exp_r, aiLower_exp_r, \
    bjEst_exp_r, bjUpper_exp_r, bjLower_exp_r, \
    gijEst_exp_r, gijUpper_exp_r, gijLower_exp_r, \
    MC_f, MC_ai, MC_bj, MC_gij = \
    Recouple_DGM2(ssrt_bern_all, ssst_bern_all, ssrt_pois_all, ssst_pois_all,\
    conditional_shift_pois, \
    TActual, unique_edges, unique_nodes, 2500, I, N);

ed = time.time()
ed - st

############################ Plotting the DGM parameters and map ############################
# plot_time = np.array([x.time().isoformat() for x in time_grid[np.arange(1, TActual+1)]])

plot_time = np.array([x.date().isoformat() + "\n" + x.time().isoformat() \
                      for x in time_grid[np.arange(1, TActual+1)]])

base_plot = plt.plot(plot_time, fEst_exp_r[0, :])
plt.plot(plot_time, MC_f[0,:], 'o', ms = 2, color="black")
plt.xticks(plot_time[np.linspace(0, len(plot_time)-1, 6, dtype=int)])
plt.fill_between(plot_time, fLower_exp_r[0, :], fUpper_exp_r[0, :], alpha=0.2)
plt.title("Baseline process")
# plt.savefig('baseline.pdf')
plt.show()

# Plot outflow process
# temp_idx = np.array([7, 6, 5, 2, 3])
temp_idx = np.flip(np.argsort(np.mean(aiEst_exp_r, axis=1))[np.arange(-10, 0)])
for idx in temp_idx:
    # idx = 8
    plt.plot(plot_time, (aiEst_exp_r[idx, :]).T)
    # plt.plot(plot_time, np.exp(MC_ai[idx, :]).T, 'o', ms = 2, color="black")
    # plt.fill_between(plot_time, (aiLower_exp_r[idx, :]).T, (aiUpper_exp_r[idx, :]).T, alpha=0.2)
    
plt.xticks(plot_time[np.linspace(0, len(plot_time)-1, 6, dtype=int)])
plt.title("outflow process (alpha_i)")
lgd = plt.legend(labels=unique_nodes[temp_idx],
           bbox_to_anchor=(1.04, 1), 
           loc="upper left")
# plt.savefig('outflow.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')
plt.show()

# Plot inflow process
for idx in temp_idx:
    plt.plot(plot_time, (bjEst_exp_r[idx, :]).T)
    # plt.fill_between(plot_time, (bjLower_exp_r[idx, :]).T, (bjUpper_exp_r[idx, :]).T, alpha=0.2)
plt.xticks(plot_time[np.linspace(0, len(plot_time)-1, 6, dtype=int)])
plt.title("inflow process (beta_j)")
lgd = plt.legend(labels=unique_nodes[temp_idx],
            bbox_to_anchor=(1.04, 1), 
            loc="upper left")
# plt.savefig('inflow.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')
plt.show()

temp_idx = np.flip(np.argsort(np.mean(gijEst_exp_r, axis=1))[np.arange(-5, 0)])
for idx in temp_idx:
    plt.plot(plot_time, gijEst_exp_r[temp_idx, :].T)
plt.xticks(plot_time[np.linspace(0, len(plot_time)-1, 6, dtype=int)])
lgd = plt.legend(labels=unique_edges[temp_idx, :],
           bbox_to_anchor=(1.04, 1), 
           loc="upper left")
plt.title("affinity process (gamma_ij)")
# plt.savefig('affinity.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')
plt.show()




# Plot Poisson Parameter
#temp_idx = np.array([7, 6, 5, 2, 3])
temp_idx = np.flip(np.argsort(np.mean(gijEst_exp_r, axis=1))[np.arange(-5, 0)])
for idx in temp_idx:
    # idx = 8
    plt.plot(plot_time, (ra_pois_mean[:, idx]))
    # plt.plot(plot_time, np.exp(MC_ai[idx, :]).T, 'o', ms = 2, color="black")
    # plt.fill_between(plot_time, (aiLower_exp_r[idx, :]).T, (aiUpper_exp_r[idx, :]).T, alpha=0.2)
    
plt.xticks(plot_time[np.linspace(0, len(plot_time)-1, 6, dtype=int)])
plt.title("Poisson Parameters")
lgd = plt.legend(labels=unique_nodes[temp_idx],
           bbox_to_anchor=(1.04, 1), 
           loc="upper left")
# plt.savefig('outflow.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')
plt.show()



bus_plot = rio.plot(alpha=0.2)
k = 0
for i in np.unique(sub_bus['line']):
    # i = 6
    bus_tmp = sub_bus.loc[sub_bus['line'] == i, :]
    xy_tmp = np.array(bus_tmp[['longitude', 'latitude']])
    plt.plot(xy_tmp[:,0], xy_tmp[:,1], ".", markersize=0.01,\
              color = list(mcolors.CSS4_COLORS.keys())[k])
    k +=1
    
for i in range(rio_grid.shape[0]):
    plt.vlines(x = rio_grid[i, 0], ymin = np.min(rio_grid[:, 1]), 
                ymax =  np.max(rio_grid[:, 1]),
            colors = 'grey', linewidth = 0.1)
    plt.hlines(y = rio_grid[i, 1], xmin = np.min(rio_grid[:, 0]), 
                xmax =  np.max(rio_grid[:, 0]),
            colors = 'grey', linewidth = 0.1)

for i in unique_nodes:
    plt.text(rio_grid[i, 0]+cell_size*0.1, rio_grid[i, 1]+cell_size*0.1,\
    str(i), size = 5)
    

for i in unique_nodes[temp_idx[range(3)]]:
    plt.vlines(x = rio_grid[i, 0], 
                ymin = rio_grid[i, 1], 
                ymax = rio_grid[i, 1]+cell_size,
            colors = 'red', linewidth = 1)
    plt.vlines(x = rio_grid[i, 0]+cell_size, 
                ymin = rio_grid[i, 1], 
                ymax = rio_grid[(i+1), 1]+cell_size,
            colors = 'red', linewidth = 1)
    
    plt.hlines(y = rio_grid[i, 1], 
                xmin = rio_grid[i, 0], 
                xmax = rio_grid[i, 0]+cell_size,
            colors = 'red', linewidth = 1)
    plt.hlines(y = rio_grid[i, 1]+cell_size, 
                xmin = rio_grid[i, 0], 
                xmax = rio_grid[i, 0]+cell_size,
            colors = 'red', linewidth = 1)
# bus_plot.set_title("Trajectory of 20 buses from 01/25-02/09")
# plt.savefig('Rio_map.pdf')
plt.show()



bus_plot = rio.plot(alpha=0.2)
k = 0
for i in np.arange(0, sim_paths.shape[0]):
    # i = 6
    sim = sim_paths[i, :]
    lat = rio_grid[sim.astype(int), 0]
    long = rio_grid[sim.astype(int), 1]
    plt.plot(lat, long, linestyle = "-", markersize=1, alpha = .01)
plt.show()
    
for i in range(rio_grid.shape[0]):
    plt.vlines(x = rio_grid[i, 0], ymin = np.min(rio_grid[:, 1]), 
                ymax =  np.max(rio_grid[:, 1]),
            colors = 'grey', linewidth = 0.1)
    plt.hlines(y = rio_grid[i, 1], xmin = np.min(rio_grid[:, 0]), 
                xmax =  np.max(rio_grid[:, 0]),
            colors = 'grey', linewidth = 0.1)

for i in unique_nodes:
    plt.text(rio_grid[i, 0]+cell_size*0.1, rio_grid[i, 1]+cell_size*0.1,\
    str(i), size = 5)
    

""" for i in unique_nodes[temp_idx[range(3)]]:
    plt.vlines(x = rio_grid[i, 0], 
                ymin = rio_grid[i, 1], 
                ymax = rio_grid[i, 1]+cell_size,
            colors = 'red', linewidth = 1)
    plt.vlines(x = rio_grid[i, 0]+cell_size, 
                ymin = rio_grid[i, 1], 
                ymax = rio_grid[(i+1), 1]+cell_size,
            colors = 'red', linewidth = 1)
    
    plt.hlines(y = rio_grid[i, 1], 
                xmin = rio_grid[i, 0], 
                xmax = rio_grid[i, 0]+cell_size,
            colors = 'red', linewidth = 1)
    plt.hlines(y = rio_grid[i, 1]+cell_size, 
                xmin = rio_grid[i, 0], 
                xmax = rio_grid[i, 0]+cell_size,
            colors = 'red', linewidth = 1) """
# bus_plot.set_title("Trajectory of 20 buses from 01/25-02/09")
# plt.savefig('Rio_map.pdf')
plt.show()